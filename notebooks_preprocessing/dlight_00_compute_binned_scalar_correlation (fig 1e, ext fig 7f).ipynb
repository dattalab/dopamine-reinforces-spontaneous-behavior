{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Here we are computing the \"binned\" correlation between dLight and scalar variables shown in Figure 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifically, in this notebook we are:\n",
    "\n",
    "1. Z-scoring the dLight data per session\n",
    "1. Binning dLight and scalars\n",
    "1. For dLight computing the average per bin and the peak rate per bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rl_analysis.io.df import dlight_exclude\n",
    "from rl_analysis.util import rle\n",
    "from functools import partial\n",
    "from sklearn.utils import shuffle\n",
    "from joblib import delayed, Parallel\n",
    "from typing import Sequence\n",
    "from contextlib import redirect_stderr\n",
    "\n",
    "import toml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "\n",
    "terminal = sys.__stderr__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load in new dlight data and preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../analysis_configuration.toml\", \"r\") as f:\n",
    "    analysis_config = toml.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dirs = analysis_config[\"raw_data\"]\n",
    "proc_dirs = analysis_config[\"intermediate_results\"]\n",
    "dlight_cfg = analysis_config[\"dlight_basic_analysis\"]\n",
    "dlight_common_cfg = analysis_config[\"dlight_common\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dlight_df = pd.read_parquet(os.path.join(raw_dirs[\"dlight\"], \"dlight_photometry_processed_full.parquet\"))\n",
    "\n",
    "signal_keys = dlight_df.filter(regex=\"(signal|reference|reref)_dff$\").columns.tolist()\n",
    "\n",
    "dlight_df[\"labels\"] = dlight_df[\"predicted_syllable (offline)\"].replace(-5, np.nan).astype(\"UInt8\")\n",
    "dlight_df = dlight_df.dropna(subset=[\"labels\"])\n",
    "\n",
    "data_keys = [\n",
    "    \"transition\",\n",
    "] + dlight_cfg[\"scalars\"]\n",
    "\n",
    "dlight_df[\"transition\"] = dlight_df.groupby(\"uuid\", group_keys=False)[\"labels\"].apply(\n",
    "    lambda x: (x.diff() != 0).astype(\"float\")\n",
    ")\n",
    "data_keys = dlight_df.columns.intersection(data_keys).tolist()\n",
    "\n",
    "transition_tstamps = dlight_df.loc[dlight_df[\"transition\"] == 1, \"timestamp\"]\n",
    "\n",
    "dlight_df[\"transition_time\"] = np.nan\n",
    "dlight_df.loc[dlight_df[\"transition\"] == 1, \"transition_time\"] = transition_tstamps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strip out the data we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal_keys_z = [f\"{_}_z\" for _ in signal_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_signal_keys = signal_keys_z\n",
    "all_signal_keys = dlight_df.columns.intersection(all_signal_keys).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rle_df = dlight_df.groupby(\"uuid\")[\"labels\"].apply(rle)\n",
    "rle_df = rle_df.dropna().astype(\"int8\")\n",
    "sorted_cats = rle_df.value_counts().index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can't cleanly exclude target so get rid of all post sessions\n",
    "use_data = dlight_exclude(\n",
    "    dlight_df, syllable_key=\"labels\", exclude_target=False, **dlight_common_cfg\n",
    ").sort_index()\n",
    "use_data = use_data.loc[\n",
    "    ~((use_data[\"opsin\"] == \"chrimson\") & (use_data[\"session_number\"].isin([3, 4])))\n",
    "].copy()\n",
    "\n",
    "cats = np.arange(len(sorted_cats))\n",
    "zdata_keys = [f\"{_}_z\" for _ in data_keys]\n",
    "\n",
    "# re-standardize dLight data so we're using comparable thresholds...\n",
    "use_data[all_signal_keys] = use_data.groupby(\"uuid\")[all_signal_keys].transform(\n",
    "    lambda x: (x - x.mean()) / x.std()\n",
    ")\n",
    "\n",
    "use_data[zdata_keys] = use_data.groupby(\"uuid\")[data_keys].transform(\n",
    "    lambda x: (x - x.mean()) / x.std()\n",
    ")\n",
    "use_data[\"labels\"] = use_data[\"labels\"].astype(\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_data[\"syllable_number\"] = (\n",
    "    use_data.groupby([\"uuid\"], group_keys=False)[\"labels\"].apply(lambda x: (x.diff() != 0).cumsum()).astype(\"uint16\")\n",
    ")\n",
    "use_data[\"uuid\"] = use_data[\"uuid\"].astype(\"category\")\n",
    "use_data[\"area\"] = use_data[\"area\"].astype(\"category\")\n",
    "use_data[\"mouse_id\"] = use_data[\"mouse_id\"].astype(\"category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "syllable_size = use_data.groupby([\"uuid\", \"syllable_number\"]).size().rename(\"duration\")\n",
    "use_data = (\n",
    "    use_data.set_index([\"uuid\", \"syllable_number\"]).join(syllable_size).reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Define some useful helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "timescales = np.arange(*dlight_cfg[\"timescale_correlation\"][\"bins\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_data[\"uuid\"] = use_data[\"uuid\"].astype(\"str\")\n",
    "use_data[\"mouse_id\"] = use_data[\"mouse_id\"].astype(\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_signal_keys = [\"signal_reref_dff_z\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def peak_rate_cross(dat: pd.DataFrame, threshold: float = 1.96):\n",
    "    values = dat.to_numpy()\n",
    "    if len(values) > 2:\n",
    "        return np.mean((values[:-1] < threshold) & (values[1:] > threshold))\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_data(\n",
    "    timescale: float,\n",
    "    all_signal_keys: Sequence[str] = all_signal_keys,\n",
    "    data_keys: Sequence[str] = data_keys + [\"labels\", \"duration\"],\n",
    "    neural_agg: str = \"mean\",\n",
    "    data_agg: str = \"mean\",\n",
    ") -> pd.DataFrame:\n",
    "\n",
    "    data = use_data\n",
    "\n",
    "    if timescale == \"syllable\":\n",
    "        time_bin = data[\"syllable_number\"]\n",
    "    else:\n",
    "        time_bin = pd.cut(\n",
    "            data[\"timestamp\"], bins=np.arange(0, 1900, timescale), labels=False\n",
    "        ).astype(\"int16\")\n",
    "\n",
    "    if neural_agg == data_agg:\n",
    "        agg_matrix = data.groupby(\n",
    "            [data[\"uuid\"], data[\"mouse_id\"], time_bin], observed=True\n",
    "        )[all_signal_keys + data_keys].agg(neural_agg)\n",
    "    else:\n",
    "        y = data.groupby([data[\"uuid\"], data[\"mouse_id\"], time_bin], observed=True)[\n",
    "            all_signal_keys\n",
    "        ].agg(neural_agg)\n",
    "        x = data.groupby([data[\"uuid\"], data[\"mouse_id\"], time_bin], observed=True)[\n",
    "            data_keys\n",
    "        ].agg(data_agg)\n",
    "        agg_matrix = x.join(y)\n",
    "\n",
    "    # only use this filter if we're not using syllable!\n",
    "    if timescale != \"syllable\":\n",
    "        # trim out data w/ missing frames and/or edge effects\n",
    "        sz = data.groupby(\n",
    "            [data[\"uuid\"], data[\"mouse_id\"], time_bin], observed=True\n",
    "        ).size()\n",
    "        modal_sz = sz.mode().iat[0]\n",
    "        agg_matrix = agg_matrix.loc[sz.loc[sz == modal_sz].index]\n",
    "\n",
    "    agg_matrix[\"timescale\"] = timescale\n",
    "\n",
    "    try:\n",
    "        agg_matrix[\"neural_agg\"] = neural_agg.__name__\n",
    "    except AttributeError:\n",
    "        agg_matrix[\"neural_agg\"] = neural_agg\n",
    "    return agg_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "242 jobs to process\n",
      "[Parallel(n_jobs=30)]: Using backend MultiprocessingBackend with 30 concurrent workers.\n",
      "[Parallel(n_jobs=30)]: Done   1 tasks      | elapsed:   19.6s\n",
      "[Parallel(n_jobs=30)]: Done  12 tasks      | elapsed:   20.9s\n",
      "[Parallel(n_jobs=30)]: Done  25 tasks      | elapsed:   23.8s\n",
      "[Parallel(n_jobs=30)]: Done  38 tasks      | elapsed:   31.4s\n",
      "[Parallel(n_jobs=30)]: Done  53 tasks      | elapsed:   35.0s\n",
      "[Parallel(n_jobs=30)]: Done  68 tasks      | elapsed:   42.6s\n",
      "[Parallel(n_jobs=30)]: Done  85 tasks      | elapsed:   49.7s\n",
      "[Parallel(n_jobs=30)]: Done 102 tasks      | elapsed:   53.7s\n",
      "[Parallel(n_jobs=30)]: Done 121 tasks      | elapsed:  1.0min\n",
      "[Parallel(n_jobs=30)]: Done 140 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=30)]: Done 161 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=30)]: Done 182 tasks      | elapsed:  1.3min\n",
      "[Parallel(n_jobs=30)]: Done 208 out of 242 | elapsed:  1.4min remaining:   13.5s\n",
      "[Parallel(n_jobs=30)]: Done 233 out of 242 | elapsed:  1.5min remaining:    3.4s\n",
      "[Parallel(n_jobs=30)]: Done 242 out of 242 | elapsed:  1.5min finished\n"
     ]
    }
   ],
   "source": [
    "func = partial(bin_data, neural_agg=peak_rate_cross)\n",
    "delays = [delayed(func)(_timescale) for _timescale in timescales]\n",
    "delays += [delayed(func)(\"syllable\")]\n",
    "\n",
    "func = partial(bin_data, neural_agg=\"mean\")\n",
    "delays += [delayed(func)(_timescale) for _timescale in timescales]\n",
    "delays += [delayed(func)(\"syllable\")]\n",
    "\n",
    "\n",
    "with redirect_stderr(terminal):\n",
    "    print(f\"{len(delays)} jobs to process\", file=terminal)\n",
    "    agg_mats = Parallel(n_jobs=30, verbose=10, backend=\"multiprocessing\")(delays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_data = pd.concat(agg_mats).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_data.loc[agg_data[\"timescale\"] == \"syllable\", \"timescale\"] = -5\n",
    "agg_data[\"timescale\"] = agg_data[\"timescale\"].astype(\"int\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_agg_data = agg_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_kwargs = {\n",
    "    \"method\": \"pearson\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = (\n",
    "    use_agg_data.dropna()\n",
    "    .groupby([\"timescale\", \"uuid\", \"neural_agg\"])[data_keys + all_signal_keys]\n",
    "    .corr(**corr_kwargs)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs.index = corrs.index.rename(\"feature\", level=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffler(\n",
    "    idx: int,\n",
    "    shuffle_col: str = \"signal_reref_dff_z\",\n",
    "    shuffle_group_by: Sequence[str] = [\"timescale\", \"uuid\", \"neural_agg\"],\n",
    "    corr_group_by: Sequence[str] = [\"timescale\", \"uuid\", \"neural_agg\"],\n",
    "    corr_keys: Sequence[str] = data_keys + all_signal_keys,\n",
    "    corr_kwargs: dict = corr_kwargs,\n",
    "):\n",
    "\n",
    "    use_df = use_agg_data.copy()\n",
    "    use_df[shuffle_col] = (\n",
    "        use_df.groupby(shuffle_group_by)[shuffle_col]\n",
    "        .apply(lambda x: shuffle(x, random_state=idx))\n",
    "        .values\n",
    "    )\n",
    "\n",
    "    corrs = use_df.groupby(corr_group_by)[corr_keys].corr(**corr_kwargs)\n",
    "    corrs.index = corrs.index.set_names(\"feature\", level=-1)\n",
    "    #     corrs = corrs.reset_index()\n",
    "    corrs[\"index\"] = idx\n",
    "    corrs = corrs.xs(shuffle_col, level=\"feature\")\n",
    "    return corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000 jobs to process\n",
      "[Parallel(n_jobs=-5)]: Using backend MultiprocessingBackend with 124 concurrent workers.\n",
      "[Parallel(n_jobs=-5)]: Done  17 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-5)]: Done  40 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-5)]: Done  65 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-5)]: Done  90 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-5)]: Done 117 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-5)]: Done 144 tasks      | elapsed:  2.0min\n",
      "[Parallel(n_jobs=-5)]: Done 173 tasks      | elapsed:  2.1min\n",
      "[Parallel(n_jobs=-5)]: Done 202 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-5)]: Done 233 tasks      | elapsed:  2.2min\n",
      "[Parallel(n_jobs=-5)]: Done 264 tasks      | elapsed:  2.9min\n",
      "[Parallel(n_jobs=-5)]: Done 297 tasks      | elapsed:  3.1min\n",
      "[Parallel(n_jobs=-5)]: Done 330 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-5)]: Done 365 tasks      | elapsed:  3.2min\n",
      "[Parallel(n_jobs=-5)]: Done 400 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-5)]: Done 437 tasks      | elapsed:  4.0min\n",
      "[Parallel(n_jobs=-5)]: Done 474 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-5)]: Done 513 tasks      | elapsed:  4.7min\n",
      "[Parallel(n_jobs=-5)]: Done 552 tasks      | elapsed:  4.9min\n",
      "[Parallel(n_jobs=-5)]: Done 593 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=-5)]: Done 634 tasks      | elapsed:  5.5min\n",
      "[Parallel(n_jobs=-5)]: Done 677 tasks      | elapsed:  5.8min\n",
      "[Parallel(n_jobs=-5)]: Done 720 tasks      | elapsed:  5.9min\n",
      "[Parallel(n_jobs=-5)]: Done 854 out of 1000 | elapsed:  6.8min remaining:  1.2min\n",
      "[Parallel(n_jobs=-5)]: Done 955 out of 1000 | elapsed:  7.6min remaining:   21.4s\n",
      "[Parallel(n_jobs=-5)]: Done 1000 out of 1000 | elapsed:  7.8min finished\n"
     ]
    }
   ],
   "source": [
    "with redirect_stderr(terminal):\n",
    "    nshuffles = dlight_cfg[\"timescale_correlation\"][\"nshuffles\"]\n",
    "    print(f\"{nshuffles} jobs to process\", file=terminal)\n",
    "    shuffle_mats = Parallel(n_jobs=-5, verbose=10, backend=\"multiprocessing\")(\n",
    "        [delayed(shuffler)(_idx) for _idx in range(nshuffles)]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffle_df = pd.concat(shuffle_mats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    corrs = corrs.xs(\"signal_reref_dff_z\", level=\"feature\")\n",
    "except KeyError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_keys = [\"mouse_id\", \"area\", \"opsin\"]\n",
    "metadata = dlight_df.drop_duplicates([\"uuid\"]).set_index(\"uuid\")[meta_keys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _key in meta_keys:\n",
    "    if _key not in corrs.index.names:\n",
    "        corrs[_key] = corrs.index.get_level_values(\"uuid\").map(metadata[_key])\n",
    "        corrs = corrs.set_index(_key, append=True)\n",
    "\n",
    "    if _key not in shuffle_df.index.names:\n",
    "        shuffle_df[_key] = shuffle_df.index.get_level_values(\"uuid\").map(metadata[_key])\n",
    "        shuffle_df = shuffle_df.set_index(_key, append=True)\n",
    "\n",
    "    agg_data[_key] = agg_data[\"uuid\"].map(metadata[_key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_data.to_parquet(\n",
    "    os.path.join(proc_dirs[\"dlight\"], \"scalar_correlations_data.parquet\")\n",
    ")\n",
    "corrs.to_parquet(\n",
    "    os.path.join(proc_dirs[\"dlight\"], \"scalar_correlations.parquet\")\n",
    ")\n",
    "shuffle_df.to_parquet(\n",
    "    os.path.join(proc_dirs[\"dlight\"], \"scalar_correlations_shuffle.parquet\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:spont-da]",
   "language": "python",
   "name": "conda-env-spont-da-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0c2fdf7cc8b041b28ad6f775feb9e1b2": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "1001a27c0c074ac198bd468374323a2e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_39ea6a6a3b094af8892ed29f09468e8e",
        "IPY_MODEL_3becade9c77a4841aaf71a133ff0c716"
       ],
       "layout": "IPY_MODEL_904831def6f4458d84d03d520d49017e"
      }
     },
     "11e5f855cc134b13a37770ba162b56d3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "135886efb36e4b1891e7b9595f5a69a7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "151fb3f16202474089e6685841e0f11c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_edae40b144fd469ca3fd80efbeff1b8d",
       "style": "IPY_MODEL_6a61457647284def89edcb0c334b4724",
       "value": " 19/19 [29:27&lt;00:00, 93.03s/it]"
      }
     },
     "23b37c61bbc24d62a47bece85cc92bdc": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3157ef96fb9c407798033e0c971c0b91": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "3320c6d509d744e6a5fbc0ef152785a7": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "39ea6a6a3b094af8892ed29f09468e8e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "description": "  5%",
       "layout": "IPY_MODEL_135886efb36e4b1891e7b9595f5a69a7",
       "max": 19,
       "style": "IPY_MODEL_f383eee0318f40ad9695f8f30d353fc7",
       "value": 1
      }
     },
     "3becade9c77a4841aaf71a133ff0c716": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_11e5f855cc134b13a37770ba162b56d3",
       "style": "IPY_MODEL_85a2ae049da942199e8ae571f375f5be",
       "value": " 1/19 [00:01&lt;00:35,  1.95s/it]"
      }
     },
     "3cb5141450ed40cb8ea4ae55f5d079e8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_563568b1258a41539b00a82d58d9a760",
        "IPY_MODEL_eb693443923b4849910c81c3e234ea0a"
       ],
       "layout": "IPY_MODEL_cfec1c73705645c09cf30a8e9eff64fa"
      }
     },
     "563568b1258a41539b00a82d58d9a760": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "100%",
       "layout": "IPY_MODEL_23b37c61bbc24d62a47bece85cc92bdc",
       "max": 19,
       "style": "IPY_MODEL_a34d88c02f764beba35e1c6f25c14088",
       "value": 19
      }
     },
     "67dea0179ff34a1d9cd1e2afb6be40bb": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "100%",
       "layout": "IPY_MODEL_ccdc1ce02d84438ba5837323959ac392",
       "max": 19,
       "style": "IPY_MODEL_d1236fd48fbe4a86b88f7e57a30a254e",
       "value": 19
      }
     },
     "6a61457647284def89edcb0c334b4724": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "85a2ae049da942199e8ae571f375f5be": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "904831def6f4458d84d03d520d49017e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "91b950b97f9f49179ac41fba04bef6ec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_c09802e74cbf465e89e98d12451db80b",
        "IPY_MODEL_b67bba143dc149aca75d6b19f991f40b"
       ],
       "layout": "IPY_MODEL_ef408cf36bf64dc5981e43291d864254"
      }
     },
     "a318aec2eccc4d5a888cd77c1d83de58": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_67dea0179ff34a1d9cd1e2afb6be40bb",
        "IPY_MODEL_151fb3f16202474089e6685841e0f11c"
       ],
       "layout": "IPY_MODEL_0c2fdf7cc8b041b28ad6f775feb9e1b2"
      }
     },
     "a34d88c02f764beba35e1c6f25c14088": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "b67bba143dc149aca75d6b19f991f40b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_3157ef96fb9c407798033e0c971c0b91",
       "style": "IPY_MODEL_d11fa8243b2e41ce9b2c2b0d76dfa8e0",
       "value": " 19/19 [02:00&lt;00:00,  6.34s/it]"
      }
     },
     "c09802e74cbf465e89e98d12451db80b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "description": "100%",
       "layout": "IPY_MODEL_3320c6d509d744e6a5fbc0ef152785a7",
       "max": 19,
       "style": "IPY_MODEL_ccbab5b38c564ff2be813f668ace192f",
       "value": 19
      }
     },
     "ccbab5b38c564ff2be813f668ace192f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "ccdc1ce02d84438ba5837323959ac392": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "cfec1c73705645c09cf30a8e9eff64fa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "d11fa8243b2e41ce9b2c2b0d76dfa8e0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "d1236fd48fbe4a86b88f7e57a30a254e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     },
     "eb693443923b4849910c81c3e234ea0a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_f164a9b92dc74eb2a9495833b2758d82",
       "style": "IPY_MODEL_ebe3845f08e44758b963aa320dd46522",
       "value": " 19/19 [00:14&lt;00:00,  1.36it/s]"
      }
     },
     "ebe3845f08e44758b963aa320dd46522": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "edae40b144fd469ca3fd80efbeff1b8d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "ef408cf36bf64dc5981e43291d864254": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f164a9b92dc74eb2a9495833b2758d82": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "f383eee0318f40ad9695f8f30d353fc7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": "initial"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
